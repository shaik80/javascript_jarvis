<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Jarvis</title>
</head>

<body>
    <!-- <button id="btn" onclick="recognition.start()">Record</button>
    <h1 id="result"></h1> -->


    <video id="video" autoplay muted></video>
    <canvas id="canvas"  style="display: none;"></canvas>
    <div id="status"></div>


    <!-- Load TensorFlow.js. This is required to use MobileNet. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.1"> </script>
    <!-- Load the MobileNet model. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0"> </script>
    <!-- Place your code in the script tag below. You can also use an external .js file -->
    <script>
        
        (async () => {
            const model = await mobilenet.load()
            const status = document.getElementById('status');
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext("2d");

            const stream = await navigator.mediaDevices.getUserMedia({
                audio: false,
                video: {
                    facingMode: 'environment'
                }
            })

            // Stream  -> raw stream of video
            video.srcObject = stream
            
            predict()

            async function predict() {
                ctx.drawImage(video, 0, 0, 500, 500)
                const predictions = await model.classify(canvas)
                status.innerHTML = `Prediction:  ${predictions[0].className}  /  ${predictions[0]}`
                requestAnimationFrame(predict)
            }
        })()
    </script>
    <script src="./js/app.js"></script>
</body>

</html>